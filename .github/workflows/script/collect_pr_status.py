#!/usr/bin/env python3
"""ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ã®ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ã— Markdown ã«æ•´å½¢ã—ã¦å‡ºåŠ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

GitHub CLI (`gh`) ã‚’åˆ©ç”¨ã—ã¦ä»¥ä¸‹ã®æƒ…å ±ã‚’åé›†ã™ã‚‹ã€‚

* ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ PR ã®åŸºæœ¬æƒ…å ±
* ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çŠ¶æ³ã‚„å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼
* Projects (v2) ã«ç´ä»˜ããƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤

`--repo` å¼•æ•°ã§å¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒªã‚’æŒ‡å®šå¯èƒ½ã§ã€ãƒªãƒã‚¸ãƒˆãƒªã”ã¨ã® Markdown ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
åé›†ã—ãŸå†…å®¹ã‚’ Wiki ã«æ²è¼‰ã™ã‚‹ãŸã‚ã® Markdown å½¢å¼ã«ã¾ã¨ã‚ã‚‹ã€‚
"""
import argparse
import datetime
import json
import os
import subprocess
import logging
import base64
from typing import List, Dict, Any, Set, Optional

# ç’°å¢ƒå¤‰æ•° LOG_LEVEL ã‚’å‚ç…§ã—ã¦ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š
LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.INFO),
    format="%(levelname)s: %(message)s",
)
logger = logging.getLogger(__name__)

def determine_pr_status(
    reviewer_states: Dict[str, str],
    is_draft: bool,
    required_reviewers: Set[str],
) -> str:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çŠ¶æ…‹ã¨å¿…é ˆãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã®æ‰¿èªçŠ¶æ³ã‹ã‚‰
    PR ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ–‡å­—åˆ—ã‚’åˆ¤å®šã™ã‚‹"""

    # ãƒ‰ãƒ©ãƒ•ãƒˆã§ã‚ã‚Œã°å¸¸ã«ãƒ‰ãƒ©ãƒ•ãƒˆã‚’è¿”ã™
    if is_draft:
        return "ãƒ‰ãƒ©ãƒ•ãƒˆ"

    # ã‚³ãƒ¡ãƒ³ãƒˆãŒä¸€ä»¶ã‚‚ãªã„å ´åˆã¯æœªãƒ¬ãƒ“ãƒ¥ãƒ¼
    if not reviewer_states or all(s == "PENDING" for s in reviewer_states.values()):
        return "æœªãƒ¬ãƒ“ãƒ¥ãƒ¼"

    # ä¿®æ­£ä¾é ¼ãŒã‚ã‚‹å ´åˆã¯ä¿®æ­£ä¾é ¼ã‚’å„ªå…ˆ
    if any(s == "CHANGES_REQUESTED" for s in reviewer_states.values()):
        return "ä¿®æ­£ä¾é ¼"

    # æ‰¿èªæ¸ˆã¿ã®åˆ¤å®š
    approvals = {u for u, s in reviewer_states.items() if s == "APPROVED"}
    required_for_pr = required_reviewers & reviewer_states.keys()
    if required_for_pr and required_for_pr.issubset(approvals):
        return "æ‰¿èªæ¸ˆã¿"
    if approvals and all(s == "APPROVED" for s in reviewer_states.values()):
        return "æ‰¿èªæ¸ˆã¿"

    # ä¸Šè¨˜ä»¥å¤–ã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­
    return "ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­"

def format_reviewer_status(reviewer: str, state: str) -> str:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼çŠ¶æ…‹ã«å¿œã˜ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼åã«çµµæ–‡å­—ã‚’ä»˜åŠ ã™ã‚‹"""
    mapping = {
        "APPROVED": "âœ…",
        "CHANGES_REQUESTED": "âŒ",
        "COMMENTED": "ğŸ’¬",
        "PENDING": "â³",
        "": "â³",
    }
    return f"{reviewer}{mapping.get(state, '')}"

def run_gh(args: List[str], input_text: Optional[str] = None) -> str:
    """gh ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—çµæœã‚’æ–‡å­—åˆ—ã§è¿”ã™

    `input_text` ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯æ¨™æº–å…¥åŠ›ã¨ã—ã¦æ¸¡ã™ã€‚
    å¤±æ•—æ™‚ã¯æ¨™æº–å‡ºåŠ›ãƒ»æ¨™æº–ã‚¨ãƒ©ãƒ¼ã®å†…å®¹ã‚’è¡¨ç¤ºã—ã¦ `CalledProcessError` ã‚’é€å‡ºã™ã‚‹ã€‚
    """
    result = subprocess.run(args, input=input_text, capture_output=True, text=True)
    if result.returncode != 0:
        # ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ãŒã‚ã‚Œã°å„ªå…ˆã—ã¦è¡¨ç¤ºã—ã€ãªã‘ã‚Œã°æ¨™æº–å‡ºåŠ›ã‚’è¡¨ç¤ºã™ã‚‹
        err_msg = (result.stderr or result.stdout).strip()
        logger.error(f"gh command failed: {err_msg}")
        raise subprocess.CalledProcessError(
            result.returncode, args, output=result.stdout, stderr=result.stderr
        )
    return result.stdout

def extract_fields(project_json: Dict[str, Any], fields: List[str]) -> Dict[str, str]:
    """Projects ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‹ã‚‰æŒ‡å®šã—ãŸé …ç›®ã ã‘ã‚’æŠœãå‡ºã™

    `fieldValues.nodes` ã«ç¾ã‚Œã‚‹è¤‡æ•°ã®å€¤ã‹ã‚‰ã€å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ã¿ã‚’
    æ¢ç´¢ã—ã¦è¿”å´ã™ã‚‹ã€‚å­˜åœ¨ã—ãªã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ "-" ã§åŸ‹ã‚ã‚‹ã€‚
    """
    result = {f: "-" for f in fields}
    nodes = (
        project_json
        .get("data", {})
        .get("node", {})
        .get("projectItems", {})
        .get("nodes", [])
    )
    for n in nodes:
        fv_nodes = n.get("fieldValues", {}).get("nodes", [])
        for fv in fv_nodes:
            name = fv.get("field", {}).get("name")
            if name not in result:
                continue
            number_value = fv.get("number")
            value = (
                fv.get("text")
                or fv.get("date")
                or fv.get("name")
                or fv.get("title")
                or (str(number_value) if number_value is not None else None)
            )
            if value:
                result[name] = value
            elif isinstance(fv.get("milestone"), dict):
                # ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³å€¤ã¯ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–ã‚Šå‡ºã™
                m_title = fv["milestone"].get("title")
                if m_title:
                    result[name] = m_title
    return result

# Project ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
PROJECT_FIELD_CATALOG_CACHE: Dict[str, Dict[str, Dict[str, Any]]] = {}

def get_first_development_issue_id(pr_node_id: str) -> Optional[str]:
    """Development ã«ç´ã¥ãæœ€åˆã® Issue ã® node ID ã‚’å–å¾—ã™ã‚‹"""
    query = (
        "query($PR_ID: ID!) {\n"
        "  node(id: $PR_ID) {\n"
        "    ... on PullRequest {\n"
        "      closingIssuesReferences(first: 20) { nodes { id } }\n"
        "      timelineItems(itemTypes: [CONNECTED_EVENT, CROSS_REFERENCED_EVENT], first: 20) {\n"
        "        nodes {\n"
        "          __typename\n"
        "          ... on ConnectedEvent { subject { ... on Issue { id } } }\n"
        "          ... on CrossReferencedEvent { source { ... on Issue { id } } }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "  }\n"
        "}\n"
    )
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"PR_ID={pr_node_id}",
        ])
        data = json.loads(res).get("data", {}).get("node", {})
        refs = data.get("closingIssuesReferences", {}).get("nodes", [])
        if refs:
            return refs[0].get("id")
        timeline = data.get("timelineItems", {}).get("nodes", [])
        for t in timeline:
            if t.get("__typename") == "ConnectedEvent":
                subj = t.get("subject", {})
                if subj.get("id") and subj.get("__typename") == "Issue":
                    return subj.get("id")
            if t.get("__typename") == "CrossReferencedEvent":
                src = t.get("source", {})
                if src.get("id") and src.get("__typename") == "Issue":
                    return src.get("id")
    except Exception as e:
        logger.error(f"Development Issue å–å¾—ã«å¤±æ•—: {e}")
    return None

def get_project_item_map(node_id: str) -> Dict[str, Dict[str, Any]]:
    """æŒ‡å®šã—ãŸ node ã® ProjectV2Item ã‚’å–å¾—ã— project_id æ¯ã«ã¾ã¨ã‚ã‚‹"""
    # Project ã‚¢ã‚¤ãƒ†ãƒ ã¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’å–å¾—ã™ã‚‹ GraphQL ã‚¯ã‚¨ãƒª
    query = (
        "query($ID: ID!) {\n"
        "  node(id: $ID) {\n"
        "    ... on Issue {\n"
        "      projectItems(first: 20) {\n"
        "        nodes {\n"
        "          id\n"
        "          project { id title }\n"
        "          fieldValues(first: 50) {\n"
        "            nodes {\n"
        "              ... on ProjectV2ItemFieldSingleSelectValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                name\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldTextValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                text\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldDateValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                date\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldIterationValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                title\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldNumberValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                number\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldMilestoneValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                milestone { title }\n"
        "              }\n"
        "            }\n"
        "          }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "    ... on PullRequest {\n"
        "      projectItems(first: 20) {\n"
        "        nodes {\n"
        "          id\n"
        "          project { id title }\n"
        "          fieldValues(first: 50) {\n"
        "            nodes {\n"
        "              ... on ProjectV2ItemFieldSingleSelectValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                name\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldTextValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                text\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldDateValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                date\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldIterationValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                title\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldNumberValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                number\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldMilestoneValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                milestone { title }\n"
        "              }\n"
        "            }\n"
        "          }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "  }\n"
        "}\n"
    )
    items: Dict[str, Dict[str, Any]] = {}
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"ID={node_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("projectItems", {})
            .get("nodes", [])
        )
        for n in nodes:
            proj = n.get("project", {})
            pid = proj.get("id")
            if not pid:
                continue
            items[pid] = {
                "project": proj,
                "item": {
                    "id": n.get("id"),
                    "projectId": pid,
                    "fieldValues": n.get("fieldValues", {}).get("nodes", []),
                },
            }
    except Exception as e:
        logger.error(f"Project ã‚¢ã‚¤ãƒ†ãƒ å–å¾—ã«å¤±æ•—: {e}")
    return items

def get_project_field_catalog(project_id: str) -> Dict[str, Dict[str, Any]]:
    """Project ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ã‚’å–å¾—ã—ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    if project_id in PROJECT_FIELD_CATALOG_CACHE:
        return PROJECT_FIELD_CATALOG_CACHE[project_id]
    query = (
        "query($PID: ID!) {\n"
        "  node(id: $PID) {\n"
        "    ... on ProjectV2 {\n"
        "      fields(first: 100) {\n"
        "        nodes {\n"
        "          ... on ProjectV2Field { id name dataType }\n"
        "          ... on ProjectV2SingleSelectField { options { id name } }\n"
        "          ... on ProjectV2IterationField { configuration { iterations { id title startDate } } }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "  }\n"
        "}\n"
    )
    catalog: Dict[str, Dict[str, Any]] = {}
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"PID={project_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("fields", {})
            .get("nodes", [])
        )
        for n in nodes:
            name = n.get("name")
            if not name:
                continue
            dtype = n.get("dataType")
            meta: Dict[str, Any] = {"fieldId": n.get("id"), "type": dtype}
            if dtype == "SINGLE_SELECT":
                meta["options"] = {o.get("name"): o.get("id") for o in n.get("options", [])}
            elif dtype == "ITERATION":
                iterations = (
                    n.get("configuration", {})
                    .get("iterations", [])
                )
                meta["iterations"] = {i.get("title"): i.get("id") for i in iterations}
            catalog[name] = meta
        PROJECT_FIELD_CATALOG_CACHE[project_id] = catalog
    except Exception as e:
        logger.error(f"Project ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å–å¾—ã«å¤±æ•—: {e}")
    return catalog

def extract_field_value_map(field_values_nodes: List[Dict[str, Any]]) -> Dict[str, Any]:
    """fieldValues ãƒãƒ¼ãƒ‰ã‹ã‚‰ {ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å: å€¤} ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã™ã‚‹"""
    result: Dict[str, Any] = {}
    for fv in field_values_nodes:
        field = fv.get("field", {})
        name = field.get("name")
        if not name:
            continue
        value = (
            fv.get("name")
            or fv.get("date")
            or fv.get("title")
            or fv.get("text")
            or fv.get("number")
        )
        if value is not None:
            result[name] = value
    return result

def update_single_select(project_id: str, item_id: str, field_id: str, option_id: str) -> None:
    """Single-select ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°ã™ã‚‹"""
    mutation = (
        "mutation($P:ID!,$I:ID!,$F:ID!,$O:ID!){\n"
        "  updateProjectV2ItemFieldValue(input:{projectId:$P,itemId:$I,fieldId:$F,value:{singleSelectOptionId:$O}}){clientMutationId}\n"
        "}\n"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"P={project_id}",
            "-f", f"I={item_id}",
            "-f", f"F={field_id}",
            "-f", f"O={option_id}",
        ])
    except Exception as e:
        logger.error(f"Single-select æ›´æ–°ã«å¤±æ•—: {e}")

def update_date(project_id: str, item_id: str, field_id: str, date: str) -> None:
    """Date ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°ã™ã‚‹"""
    mutation = (
        "mutation($P:ID!,$I:ID!,$F:ID!,$D:Date!){\n"
        "  updateProjectV2ItemFieldValue(input:{projectId:$P,itemId:$I,fieldId:$F,value:{date:$D}}){clientMutationId}\n"
        "}\n"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"P={project_id}",
            "-f", f"I={item_id}",
            "-f", f"F={field_id}",
            "-f", f"D={date}",
        ])
    except Exception as e:
        logger.error(f"Date æ›´æ–°ã«å¤±æ•—: {e}")

def update_iteration(project_id: str, item_id: str, field_id: str, iteration_id: str) -> None:
    """Iteration ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°ã™ã‚‹"""
    mutation = (
        "mutation($P:ID!,$I:ID!,$F:ID!,$T:ID!){\n"
        "  updateProjectV2ItemFieldValue(input:{projectId:$P,itemId:$I,fieldId:$F,value:{iterationId:$T}}){clientMutationId}\n"
        "}\n"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"P={project_id}",
            "-f", f"I={item_id}",
            "-f", f"F={field_id}",
            "-f", f"T={iteration_id}",
        ])
    except Exception as e:
        logger.error(f"Iteration æ›´æ–°ã«å¤±æ•—: {e}")

def sync_if_empty_same_project(pr_item: Dict[str, Any], issue_item: Dict[str, Any], field_catalog: Dict[str, Dict[str, Any]]) -> None:
    """PR å´ãŒç©ºæ¬„ã®å ´åˆã« Issue å´ã®å€¤ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹"""
    want = ["Priority", "Target Date", "Sprint"]
    pr_map = extract_field_value_map(pr_item.get("fieldValues", []))
    issue_map = extract_field_value_map(issue_item.get("fieldValues", []))
    for fname in want:
        pr_v = pr_map.get(fname)
        issue_v = issue_map.get(fname)
        if (pr_v is None or pr_v == "") and issue_v:
            fmeta = field_catalog.get(fname)
            if not fmeta:
                continue
            if fmeta["type"] == "SINGLE_SELECT":
                opt_id = fmeta.get("options", {}).get(issue_v)
                if opt_id:
                    update_single_select(pr_item["projectId"], pr_item["id"], fmeta["fieldId"], opt_id)
            elif fmeta["type"] == "DATE":
                update_date(pr_item["projectId"], pr_item["id"], fmeta["fieldId"], issue_v)
            elif fmeta["type"] == "ITERATION":
                it_id = fmeta.get("iterations", {}).get(issue_v)
                if it_id:
                    update_iteration(pr_item["projectId"], pr_item["id"], fmeta["fieldId"], it_id)

def get_assignee_user_ids_for_pr(pr_node_id: str) -> List[str]:
    """PR ã®ã‚¢ã‚µã‚¤ãƒ³æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼ ID ã‚’å–å¾—ã™ã‚‹"""
    query = (
        "query($ID:ID!){ node(id:$ID){ ... on PullRequest { assignees(first:100){ nodes { id } } } } }"
    )
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"ID={pr_node_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("assignees", {})
            .get("nodes", [])
        )
        return [n.get("id") for n in nodes if n.get("id")]
    except Exception as e:
        logger.error(f"PR ã‚¢ã‚µã‚¤ãƒ³å–å¾—ã«å¤±æ•—: {e}")
        return []

def get_assignee_user_ids_for_issue(issue_node_id: str) -> List[str]:
    """Issue ã®ã‚¢ã‚µã‚¤ãƒ³æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼ ID ã‚’å–å¾—ã™ã‚‹"""
    query = (
        "query($ID:ID!){ node(id:$ID){ ... on Issue { assignees(first:100){ nodes { id } } } } }"
    )
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"ID={issue_node_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("assignees", {})
            .get("nodes", [])
        )
        return [n.get("id") for n in nodes if n.get("id")]
    except Exception as e:
        logger.error(f"Issue ã‚¢ã‚µã‚¤ãƒ³å–å¾—ã«å¤±æ•—: {e}")
        return []

def add_assignees_to_assignable(assignable_id: str, user_ids: List[str]) -> None:
    """æŒ‡å®šã—ãŸ assignable ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚¢ã‚µã‚¤ãƒ³ã™ã‚‹"""
    mutation = (
        "mutation($A:ID!,$U:[ID!]!){ addAssigneesToAssignable(input:{assignableId:$A,assigneeIds:$U}){clientMutationId} }"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"A={assignable_id}",
            # assigneeIds ã«ã¯ JSON é…åˆ—ã‚’ãã®ã¾ã¾æ¸¡ã™
            "-f", f"U={json.dumps(user_ids)}",
        ])
    except Exception as e:
        logger.error(f"ã‚¢ã‚µã‚¤ãƒ³è¿½åŠ ã«å¤±æ•—: {e}")

def sync_pr_assignees_if_empty_from_issue(pr_node_id: str, issue_node_id: str) -> None:
    """PR ã«ã‚¢ã‚µã‚¤ãƒ³ãŒç„¡ã„å ´åˆ Issue ã®ã‚¢ã‚µã‚¤ãƒ³ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹"""
    pr_assignees = get_assignee_user_ids_for_pr(pr_node_id)
    if pr_assignees:
        return
    issue_assignees = get_assignee_user_ids_for_issue(issue_node_id)
    if issue_assignees:
        add_assignees_to_assignable(pr_node_id, issue_assignees)

def main(output_dir: str, repo: str = "") -> None:
    os.makedirs(output_dir, exist_ok=True)
    # å–å¾—å¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’æ±ºå®šã—ã€gh ã‚³ãƒãƒ³ãƒ‰ç”¨ã®å¼•æ•°ã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çµ„ã¿ç«‹ã¦ã‚‹
    if repo:
        repo_arg = ["--repo", repo]
        file_suffix = repo.replace("/", "_")
    else:
        repo_env = os.environ.get("GITHUB_REPOSITORY", "")
        repo = repo_env
        repo_arg = ["--repo", repo] if repo else []
        file_suffix = repo.replace("/", "_") if repo else "unknown"
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ <ãƒªãƒã‚¸ãƒˆãƒªå>_PR_status.md å½¢å¼ã§ç”Ÿæˆ
    output_file = os.path.join(output_dir, f"{file_suffix}_PR_status.md")

    # ç’°å¢ƒå¤‰æ•° LOGIN_USERS_B64 ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨çµ„ç¹”ã®å¯¾å¿œè¡¨ã‚’ä½œæˆ
    login_user_map: Dict[str, str] = {}
    org_order: List[str] = []
    required_reviewers: Set[str] = set()
    encoded = os.environ.get("LOGIN_USERS_B64")
    if encoded:
        try:
            decoded = base64.b64decode(encoded).decode()
            login_users_json = json.loads(decoded)
            logger.debug(
                f"LOGIN_USERS_JSON={json.dumps(login_users_json, ensure_ascii=False)}"
            )  # ãƒ‡ã‚³ãƒ¼ãƒ‰çµæœã‚’å‡ºåŠ›
            for item in login_users_json.get("loginUsers", []):
                login = item.get("loginUser")
                org = item.get("organization")
                required = item.get("requiredReviewer")
                if login and org:
                    login_user_map[login] = org
                    if org not in org_order:
                        org_order.append(org)
                    if required:
                        required_reviewers.add(login)
        except Exception as e:
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚„ JSON ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦ç©ºã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’åˆ©ç”¨ã™ã‚‹
            logger.error(f"LOGIN_USERS_B64 decode failed: {e}")
    else:
        logger.warning("LOGIN_USERS_B64 is not set")

    # Markdown ã®ãƒ˜ãƒƒãƒ€ã‚’å‹•çš„ã«ç”Ÿæˆã™ã‚‹
    reviewer_cols = [f"{org} Reviewers" for org in org_order + ["other"]]
    header_cols = [
        "PR",
        "Title",
        "çŠ¶æ…‹",
        *reviewer_cols,
        "Assignees",
        "Status",
        "Priority",
        "Target Date",
        "Sprint",
    ]
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"# Pull Request Status for {repo}\n\n")
        f.write(f"Updated: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\n\n")
        f.write("| " + " | ".join(header_cols) + " |\n")
        f.write("| " + " | ".join(["---"] * len(header_cols)) + " |\n")

    # 1. ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ã® PR ä¸€è¦§ã‚’å–å¾—
    #    number ã‚„ title ãªã©ã®åŸºæœ¬æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ JSON å½¢å¼ã§å–å¾—ã™ã‚‹
    pr_list_cmd = [
        "gh", "pr", "list", "--state", "open", "--limit", "100",
        "--json", "number,title,author,createdAt,updatedAt,url,isDraft",
    ] + repo_arg
    pr_list_json = run_gh(pr_list_cmd)
    logger.debug(f"PR_LIST={pr_list_json}")
    pr_list = json.loads(pr_list_json)

    for pr in pr_list:
        # 2. PR è©³ç´°ã‚’å–å¾—
        #    ãƒ¬ãƒ“ãƒ¥ãƒ¼å±¥æ­´(reviews)ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼(reviewRequests)ã€ã‚¢ã‚µã‚¤ãƒ³(assignees)ã‚’å–å¾—ã™ã‚‹
        number = pr["number"]
        title = pr["title"].replace("\n", " ").replace("|", "\\|")
        url = pr["url"]
        is_draft = pr.get("isDraft", False)

        details_cmd = [
            "gh", "pr", "view", str(number), "--json", "reviews,reviewRequests,assignees",
        ] + repo_arg
        details_json = run_gh(details_cmd)
        logger.debug(f"DETAILS for PR {number}={details_json}")
        details = json.loads(details_json)
        reviews = details.get("reviews", [])
        requested = [r["login"] for r in details.get("reviewRequests", [])]
        assignees = [a["login"] for a in details.get("assignees", [])]
        assignees_str = " ".join(assignees) if assignees else "æœªå‰²å½“"

        # ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã”ã¨ã®æœ€æ–°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¿æŒã™ã‚‹è¾æ›¸
        reviewer_states = {r: "PENDING" for r in requested}
        # submittedAt ã§æ˜‡é †ã«ä¸¦ã¹æ›¿ãˆã¦æœ€æ–°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åæ˜ ã™ã‚‹
        sorted_reviews = sorted(
            reviews, key=lambda x: x.get("submittedAt", "")
        )
        for r in sorted_reviews:
            author = r.get("author")
            if not author:
                continue
            login = author.get("login")
            if not login:
                continue
            # ç¾åœ¨ãƒ¬ãƒ“ãƒ¥ãƒ¼å†ä¾é ¼ä¸­ã®ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã¯ä¿ç•™çŠ¶æ…‹ã®ã¾ã¾ã«ã™ã‚‹
            if login in requested:
                continue
            # åŒä¸€ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ãŒè¤‡æ•°å›ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸå ´åˆã¯æœ€å¾Œã®çŠ¶æ…‹ã‚’æ¡ç”¨ã™ã‚‹
            reviewer_states[login] = r.get("state", "")
        # çµ„ç¹”ã”ã¨ã«ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã‚’åˆ†é¡ã—å„åˆ—ã«è¡¨ç¤ºã™ã‚‹æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹
        org_groups: Dict[str, List[str]] = {org: [] for org in org_order}
        org_groups["other"] = []
        for reviewer, state in reviewer_states.items():
            org = login_user_map.get(reviewer, "other")
            org_groups.setdefault(org, []).append(
                format_reviewer_status(reviewer, state)
            )

        pr_status = determine_pr_status(reviewer_states, is_draft, required_reviewers)

        # 3. Projects (v2) ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’ GraphQL ã§å–å¾—
        #    ã¾ãš gh pr view ã§ PR ã® node ID ã‚’å–å¾—ã™ã‚‹
        node_cmd = ["gh", "pr", "view", str(number), "--json", "id", "-q", ".id"] + repo_arg
        pr_node_id = run_gh(node_cmd).strip()
        logger.debug(f"PR_NODE_ID for PR {number}={pr_node_id}")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã«ç´ä»˜ãä»»æ„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å–å¾—ã™ã‚‹ã‚¯ã‚¨ãƒª
        # PullRequest ã® projectItems ã‹ã‚‰ fieldValues ã‚’åˆ—æŒ™ã—ã€
        # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‹ã”ã¨ã« name/text/date ãªã©ã®å€¤ã‚’å–ã‚Šå‡ºã™
        graphql_query = (
            "query($PR_NODE_ID: ID!) {\n"
            "  node(id: $PR_NODE_ID) {\n"
            "    ... on PullRequest {\n"
            "      projectItems(first: 1) {\n"
            "        nodes {\n"
            "          fieldValues(first: 20) {\n"
            "            nodes {\n"
            "              __typename\n"
            "              ... on ProjectV2ItemFieldSingleSelectValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                name\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldTextValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                text\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldDateValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                date\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldIterationValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                title\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldNumberValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                number\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldMilestoneValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                milestone { title }\n"
            "              }\n"
            "            }\n"
            "          }\n"
            "        }\n"
            "      }\n"
            "    }\n"
            "  }\n"
            "}\n"
        )
        # ä¸Šè¨˜ã‚¯ã‚¨ãƒªã‚’ gh api graphql ã§å®Ÿè¡Œã—ã¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’å–å¾—ã™ã‚‹
        try:
            project_json_str = run_gh([
                "gh", "api", "graphql",
                "-f", f"query={graphql_query}", "-f", f"PR_NODE_ID={pr_node_id}",
            ])
            logger.debug(f"PROJECT_JSON for PR {number}={project_json_str}")
            project_json = json.loads(project_json_str)
            field_names = [
                "Status",
                "Priority",
                "Target Date",
                "Sprint",
            ]
            field_values = extract_fields(project_json, field_names)
            status = field_values["Status"]
            priority = field_values["Priority"]
            target_date = field_values["Target Date"]
            sprint = field_values["Sprint"]
        except subprocess.CalledProcessError as e:
            # gh ã‚³ãƒãƒ³ãƒ‰ãŒå¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›ã—ã€å€¤ã‚’ "-" ã¨ã™ã‚‹
            logger.error(f"PROJECT_JSON fetch failed for PR {number}: {e.stderr}")
            status = priority = target_date = sprint = "-"
        except json.JSONDecodeError as e:
            # JSON ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã‚‚å€¤ã‚’ "-" ã¨ã™ã‚‹
            logger.error(f"PROJECT_JSON parse failed for PR {number}: {e}")
            status = priority = target_date = sprint = "-"

        # Markdown å‡ºåŠ›ç”¨ã®è¡Œã‚’çµ„ã¿ç«‹ã¦ã‚‹
        row_fields: List[str] = [
            f"#{number}",
            f"[{title}]({url})",
            pr_status,
        ]
        for org in org_order + ["other"]:
            names = org_groups.get(org)
            row_fields.append(" ".join(names) if names else "-")
        row_fields.extend(
            [assignees_str, status, priority, target_date, sprint]
        )
        row = "| " + " | ".join(row_fields) + " |\n"
        with open(output_file, "a", encoding="utf-8") as f:
            f.write(row)

        # PR æƒ…å ±åé›†å¾Œã« Issue ã¨ã®åŒæœŸå‡¦ç†ã‚’å®Ÿè¡Œ
        try:
            issue_id = get_first_development_issue_id(pr_node_id)
            if issue_id:
                pr_items = get_project_item_map(pr_node_id)
                issue_items = get_project_item_map(issue_id)
                for pid, pr_item in pr_items.items():
                    issue_item = issue_items.get(pid)
                    if not issue_item:
                        continue
                    catalog = get_project_field_catalog(pid)
                    sync_if_empty_same_project(pr_item["item"], issue_item["item"], catalog)
                sync_pr_assignees_if_empty_from_issue(pr_node_id, issue_id)
        except Exception as e:
            logger.error(f"åŒæœŸå‡¦ç†ã«å¤±æ•—: {e}")

    logger.info(f"PR æƒ…å ±ã‚’ {output_file} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PR æƒ…å ±ã‚’åé›†ã—ã¦ Markdown ã«å‡ºåŠ›ã—ã¾ã™")
    parser.add_argument("output_dir", nargs="?", default=".")
    parser.add_argument("--repo", help="å¯¾è±¡ã¨ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒª (owner/name)", default="")
    args = parser.parse_args()
    main(args.output_dir, args.repo)
