#!/usr/bin/env python3
"""„Ç™„Éº„Éó„É≥‰∏≠„ÅÆ„Éó„É´„É™„ÇØ„Ç®„Çπ„ÉàÊÉÖÂ†±„ÇíÂèñÂæó„Åó Markdown „Å´Êï¥ÂΩ¢„Åó„Å¶Âá∫Âäõ„Åô„Çã„Çπ„ÇØ„É™„Éó„Éà

GitHub CLI (`gh`) „ÇíÂà©Áî®„Åó„Å¶‰ª•‰∏ã„ÅÆÊÉÖÂ†±„ÇíÂèéÈõÜ„Åô„Çã„ÄÇ

* „Ç™„Éº„Éó„É≥‰∏≠ PR „ÅÆÂü∫Êú¨ÊÉÖÂ†±
* „É¨„Éì„É•„Éº„ÅÆÁä∂Ê≥Å„ÇÑÂâ≤„ÇäÂΩì„Å¶„Çâ„Çå„Åü„É¨„Éì„É•„ÉØ„Éº
* Projects (v2) „Å´Á¥ê‰ªò„Åè„Éï„Ç£„Éº„É´„ÉâÂÄ§

`--repo` ÂºïÊï∞„ÅßÂØæË±°„É™„Éù„Ç∏„Éà„É™„ÇíÊåáÂÆöÂèØËÉΩ„Åß„ÄÅ„É™„Éù„Ç∏„Éà„É™„Åî„Å®„ÅÆ Markdown „ÇíÂá∫Âäõ„Åô„Çã„ÄÇ
ÂèéÈõÜ„Åó„ÅüÂÜÖÂÆπ„Çí Wiki „Å´Êé≤Ëºâ„Åô„Çã„Åü„ÇÅ„ÅÆ Markdown ÂΩ¢Âºè„Å´„Åæ„Å®„ÇÅ„Çã„ÄÇ
"""
import argparse
import datetime
import json
import os
import subprocess
import logging
import base64
from typing import List, Dict, Any, Set, Optional

# Áí∞Â¢ÉÂ§âÊï∞ LOG_LEVEL „ÇíÂèÇÁÖß„Åó„Å¶„É≠„Ç∞„É¨„Éô„É´„ÇíË®≠ÂÆö
LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.INFO),
    format="%(levelname)s: %(message)s",
)
logger = logging.getLogger(__name__)

def determine_pr_status(
    reviewer_states: Dict[str, str],
    is_draft: bool,
    required_reviewers: Set[str],
) -> str:
    """„É¨„Éì„É•„Éº„ÅÆÁä∂ÊÖã„Å®ÂøÖÈ†à„É¨„Éì„É•„ÉØ„Éº„ÅÆÊâøË™çÁä∂Ê≥Å„Åã„Çâ
    PR „ÅÆ„Çπ„ÉÜ„Éº„Çø„ÇπÊñáÂ≠óÂàó„ÇíÂà§ÂÆö„Åô„Çã"""

    # „Éâ„É©„Éï„Éà„Åß„ÅÇ„Çå„Å∞Â∏∏„Å´„Éâ„É©„Éï„Éà„ÇíËøî„Åô
    if is_draft:
        return "„Éâ„É©„Éï„Éà"

    # „Ç≥„É°„É≥„Éà„Åå‰∏Ä‰ª∂„ÇÇ„Å™„ÅÑÂ†¥Âêà„ÅØÊú™„É¨„Éì„É•„Éº
    if not reviewer_states or all(s == "PENDING" for s in reviewer_states.values()):
        return "Êú™„É¨„Éì„É•„Éº"

    # ‰øÆÊ≠£‰æùÈ†º„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØ‰øÆÊ≠£‰æùÈ†º„ÇíÂÑ™ÂÖà
    if any(s == "CHANGES_REQUESTED" for s in reviewer_states.values()):
        return "‰øÆÊ≠£‰æùÈ†º"

    # ÊâøË™çÊ∏à„Åø„ÅÆÂà§ÂÆö
    approvals = {u for u, s in reviewer_states.items() if s == "APPROVED"}
    required_for_pr = required_reviewers & reviewer_states.keys()
    if required_for_pr and required_for_pr.issubset(approvals):
        return "ÊâøË™çÊ∏à„Åø"
    if approvals and all(s == "APPROVED" for s in reviewer_states.values()):
        return "ÊâøË™çÊ∏à„Åø"

    # ‰∏äË®ò‰ª•Â§ñ„ÅØ„É¨„Éì„É•„Éº‰∏≠
    return "„É¨„Éì„É•„Éº‰∏≠"

def format_reviewer_status(reviewer: str, state: str) -> str:
    """„É¨„Éì„É•„ÉºÁä∂ÊÖã„Å´Âøú„Åò„Å¶„É¨„Éì„É•„ÉØ„ÉºÂêç„Å´ÁµµÊñáÂ≠ó„Çí‰ªòÂä†„Åô„Çã"""
    mapping = {
        "APPROVED": "‚úÖ",
        "CHANGES_REQUESTED": "‚ùå",
        "COMMENTED": "üí¨",
        "PENDING": "‚è≥",
        "": "‚è≥",
    }
    return f"{reviewer}{mapping.get(state, '')}"

def run_gh(args: List[str], input_text: Optional[str] = None) -> str:
    """gh „Ç≥„Éû„É≥„Éâ„ÇíÂÆüË°å„ÅóÁµêÊûú„ÇíÊñáÂ≠óÂàó„ÅßËøî„Åô

    `input_text` „ÅåÊåáÂÆö„Åï„Çå„ÅüÂ†¥Âêà„ÅØÊ®ôÊ∫ñÂÖ•Âäõ„Å®„Åó„Å¶Ê∏°„Åô„ÄÇ
    Â§±ÊïóÊôÇ„ÅØÊ®ôÊ∫ñÂá∫Âäõ„ÉªÊ®ôÊ∫ñ„Ç®„É©„Éº„ÅÆÂÜÖÂÆπ„ÇíË°®Á§∫„Åó„Å¶ `CalledProcessError` „ÇíÈÄÅÂá∫„Åô„Çã„ÄÇ
    """
    result = subprocess.run(args, input=input_text, capture_output=True, text=True)
    if result.returncode != 0:
        # „Ç®„É©„ÉºÂá∫Âäõ„Åå„ÅÇ„Çå„Å∞ÂÑ™ÂÖà„Åó„Å¶Ë°®Á§∫„Åó„ÄÅ„Å™„Åë„Çå„Å∞Ê®ôÊ∫ñÂá∫Âäõ„ÇíË°®Á§∫„Åô„Çã
        err_msg = (result.stderr or result.stdout).strip()
        logger.error(f"gh command failed: {err_msg}")
        raise subprocess.CalledProcessError(
            result.returncode, args, output=result.stdout, stderr=result.stderr
        )
    return result.stdout

def extract_fields(project_json: Dict[str, Any], fields: List[str]) -> Dict[str, str]:
    """Projects „ÅÆ„Éï„Ç£„Éº„É´„ÉâÂÄ§„Åã„ÇâÊåáÂÆö„Åó„ÅüÈ†ÖÁõÆ„Å†„Åë„ÇíÊäú„ÅçÂá∫„Åô

    `fieldValues.nodes` „Å´Áèæ„Çå„ÇãË§áÊï∞„ÅÆÂÄ§„Åã„Çâ„ÄÅÂøÖË¶Å„Å™„Éï„Ç£„Éº„É´„ÉâÂêç„ÅÆ„Åø„Çí
    Êé¢Á¥¢„Åó„Å¶ËøîÂç¥„Åô„Çã„ÄÇÂ≠òÂú®„Åó„Å™„ÅÑ„Éï„Ç£„Éº„É´„Éâ„ÅØ "-" „ÅßÂüã„ÇÅ„Çã„ÄÇ
    """
    result = {f: "-" for f in fields}
    nodes = (
        project_json
        .get("data", {})
        .get("node", {})
        .get("projectItems", {})
        .get("nodes", [])
    )
    for n in nodes:
        fv_nodes = n.get("fieldValues", {}).get("nodes", [])
        for fv in fv_nodes:
            name = fv.get("field", {}).get("name")
            if name not in result:
                continue
            number_value = fv.get("number")
            value = (
                fv.get("text")
                or fv.get("date")
                or fv.get("name")
                or fv.get("title")
                or (str(number_value) if number_value is not None else None)
            )
            if value:
                result[name] = value
            elif isinstance(fv.get("milestone"), dict):
                # „Éû„Ç§„É´„Çπ„Éà„Éº„É≥ÂÄ§„ÅØ„Çø„Ç§„Éà„É´„ÇíÂèñ„ÇäÂá∫„Åô
                m_title = fv["milestone"].get("title")
                if m_title:
                    result[name] = m_title
    return result

# Project „Éï„Ç£„Éº„É´„ÉâÂÆöÁæ©„ÅÆ„Ç≠„É£„ÉÉ„Ç∑„É•
PROJECT_FIELD_CATALOG_CACHE: Dict[str, Dict[str, Dict[str, Any]]] = {}

def get_first_development_issue_id(pr_node_id: str) -> Optional[str]:
    """Development „Å´Á¥ê„Å•„ÅèÊúÄÂàù„ÅÆ Issue „ÅÆ node ID „ÇíÂèñÂæó„Åô„Çã"""
    query = (
        "query($PR_ID: ID!) {\n"
        "  node(id: $PR_ID) {\n"
        "    ... on PullRequest {\n"
        "      closingIssuesReferences(first: 20) { nodes { id } }\n"
        "      timelineItems(itemTypes: [CONNECTED_EVENT, CROSS_REFERENCED_EVENT], first: 20) {\n"
        "        nodes {\n"
        "          __typename\n"
        "          ... on ConnectedEvent { subject { ... on Issue { id } } }\n"
        "          ... on CrossReferencedEvent { source { ... on Issue { id } } }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "  }\n"
        "}\n"
    )
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"PR_ID={pr_node_id}",
        ])
        data = json.loads(res).get("data", {}).get("node", {})
        refs = data.get("closingIssuesReferences", {}).get("nodes", [])
        if refs:
            return refs[0].get("id")
        timeline = data.get("timelineItems", {}).get("nodes", [])
        for t in timeline:
            if t.get("__typename") == "ConnectedEvent":
                subj = t.get("subject", {})
                if subj.get("id") and subj.get("__typename") == "Issue":
                    return subj.get("id")
            if t.get("__typename") == "CrossReferencedEvent":
                src = t.get("source", {})
                if src.get("id") and src.get("__typename") == "Issue":
                    return src.get("id")
    except Exception as e:
        logger.error(f"Development Issue ÂèñÂæó„Å´Â§±Êïó: {e}")
    return None

def get_project_item_map(node_id: str) -> Dict[str, Dict[str, Any]]:
    """ÊåáÂÆö„Åó„Åü node „ÅÆ ProjectV2Item „ÇíÂèñÂæó„Åó project_id ÊØé„Å´„Åæ„Å®„ÇÅ„Çã"""
    # Project „Ç¢„Ç§„ÉÜ„É†„Å®„Éï„Ç£„Éº„É´„ÉâÂÄ§„ÇíÂèñÂæó„Åô„Çã GraphQL „ÇØ„Ç®„É™
    query = (
        "query($ID: ID!) {\n"
        "  node(id: $ID) {\n"
        "    ... on Issue {\n"
        "      projectItems(first: 20) {\n"
        "        nodes {\n"
        "          id\n"
        "          project { id title }\n"
        "          fieldValues(first: 50) {\n"
        "            nodes {\n"
        "              ... on ProjectV2ItemFieldSingleSelectValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                name\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldTextValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                text\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldDateValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                date\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldIterationValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                title\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldNumberValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                number\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldMilestoneValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                milestone { title }\n"
        "              }\n"
        "            }\n"
        "          }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "    ... on PullRequest {\n"
        "      projectItems(first: 20) {\n"
        "        nodes {\n"
        "          id\n"
        "          project { id title }\n"
        "          fieldValues(first: 50) {\n"
        "            nodes {\n"
        "              ... on ProjectV2ItemFieldSingleSelectValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                name\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldTextValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                text\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldDateValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                date\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldIterationValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                title\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldNumberValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                number\n"
        "              }\n"
        "              ... on ProjectV2ItemFieldMilestoneValue {\n"
        "                field { ... on ProjectV2FieldCommon { name } }\n"
        "                milestone { title }\n"
        "              }\n"
        "            }\n"
        "          }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "  }\n"
        "}\n"
    )
    items: Dict[str, Dict[str, Any]] = {}
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"ID={node_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("projectItems", {})
            .get("nodes", [])
        )
        for n in nodes:
            proj = n.get("project", {})
            pid = proj.get("id")
            if not pid:
                continue
            items[pid] = {
                "project": proj,
                "item": {
                    "id": n.get("id"),
                    "projectId": pid,
                    "fieldValues": n.get("fieldValues", {}).get("nodes", []),
                },
            }
    except Exception as e:
        logger.error(f"Project „Ç¢„Ç§„ÉÜ„É†ÂèñÂæó„Å´Â§±Êïó: {e}")
    return items

def get_project_field_catalog(project_id: str) -> Dict[str, Dict[str, Any]]:
    """Project „ÅÆ„Éï„Ç£„Éº„É´„ÉâÂÆöÁæ©„ÇíÂèñÂæó„Åó„Ç≠„É£„ÉÉ„Ç∑„É•„Åô„Çã"""
    if project_id in PROJECT_FIELD_CATALOG_CACHE:
        return PROJECT_FIELD_CATALOG_CACHE[project_id]
    query = (
        "query($PID: ID!) {\n"
        "  node(id: $PID) {\n"
        "    ... on ProjectV2 {\n"
        "      fields(first: 100) {\n"
        "        nodes {\n"
        "          ... on ProjectV2Field { id name dataType }\n"
        "          ... on ProjectV2SingleSelectField { options { id name } }\n"
        "          ... on ProjectV2IterationField { configuration { iterations { id title startDate } } }\n"
        "        }\n"
        "      }\n"
        "    }\n"
        "  }\n"
        "}\n"
    )
    catalog: Dict[str, Dict[str, Any]] = {}
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"PID={project_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("fields", {})
            .get("nodes", [])
        )
        for n in nodes:
            name = n.get("name")
            if not name:
                continue
            dtype = n.get("dataType")
            meta: Dict[str, Any] = {"fieldId": n.get("id"), "type": dtype}
            if dtype == "SINGLE_SELECT":
                meta["options"] = {o.get("name"): o.get("id") for o in n.get("options", [])}
            elif dtype == "ITERATION":
                iterations = (
                    n.get("configuration", {})
                    .get("iterations", [])
                )
                meta["iterations"] = {i.get("title"): i.get("id") for i in iterations}
            catalog[name] = meta
        PROJECT_FIELD_CATALOG_CACHE[project_id] = catalog
    except Exception as e:
        logger.error(f"Project „Éï„Ç£„Éº„É´„ÉâÂèñÂæó„Å´Â§±Êïó: {e}")
    return catalog

def extract_field_value_map(field_values_nodes: List[Dict[str, Any]]) -> Dict[str, Any]:
    """fieldValues „Éé„Éº„Éâ„Åã„Çâ {„Éï„Ç£„Éº„É´„ÉâÂêç: ÂÄ§} „Éû„ÉÉ„Éó„ÇíÁîüÊàê„Åô„Çã"""
    result: Dict[str, Any] = {}
    for fv in field_values_nodes:
        field = fv.get("field", {})
        name = field.get("name")
        if not name:
            continue
        value = (
            fv.get("name")
            or fv.get("date")
            or fv.get("title")
            or fv.get("text")
            or fv.get("number")
        )
        if value is not None:
            result[name] = value
    return result

def update_single_select(project_id: str, item_id: str, field_id: str, option_id: str) -> None:
    """Single-select „Éï„Ç£„Éº„É´„Éâ„ÇíÊõ¥Êñ∞„Åô„Çã"""
    mutation = (
        "mutation($P:ID!,$I:ID!,$F:ID!,$O:ID!){\n"
        "  updateProjectV2ItemFieldValue(input:{projectId:$P,itemId:$I,fieldId:$F,value:{singleSelectOptionId:$O}}){clientMutationId}\n"
        "}\n"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"P={project_id}",
            "-f", f"I={item_id}",
            "-f", f"F={field_id}",
            "-f", f"O={option_id}",
        ])
    except Exception as e:
        logger.error(f"Single-select Êõ¥Êñ∞„Å´Â§±Êïó: {e}")

def update_date(project_id: str, item_id: str, field_id: str, date: str) -> None:
    """Date „Éï„Ç£„Éº„É´„Éâ„ÇíÊõ¥Êñ∞„Åô„Çã"""
    mutation = (
        "mutation($P:ID!,$I:ID!,$F:ID!,$D:Date!){\n"
        "  updateProjectV2ItemFieldValue(input:{projectId:$P,itemId:$I,fieldId:$F,value:{date:$D}}){clientMutationId}\n"
        "}\n"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"P={project_id}",
            "-f", f"I={item_id}",
            "-f", f"F={field_id}",
            "-f", f"D={date}",
        ])
    except Exception as e:
        logger.error(f"Date Êõ¥Êñ∞„Å´Â§±Êïó: {e}")

def update_iteration(project_id: str, item_id: str, field_id: str, iteration_id: str) -> None:
    """Iteration „Éï„Ç£„Éº„É´„Éâ„ÇíÊõ¥Êñ∞„Åô„Çã"""
    mutation = (
        "mutation($P:ID!,$I:ID!,$F:ID!,$T:ID!){\n"
        "  updateProjectV2ItemFieldValue(input:{projectId:$P,itemId:$I,fieldId:$F,value:{iterationId:$T}}){clientMutationId}\n"
        "}\n"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"P={project_id}",
            "-f", f"I={item_id}",
            "-f", f"F={field_id}",
            "-f", f"T={iteration_id}",
        ])
    except Exception as e:
        logger.error(f"Iteration Êõ¥Êñ∞„Å´Â§±Êïó: {e}")

def sync_if_empty_same_project(pr_item: Dict[str, Any], issue_item: Dict[str, Any], field_catalog: Dict[str, Dict[str, Any]]) -> None:
    """PR ÂÅ¥„ÅåÁ©∫Ê¨Ñ„ÅÆÂ†¥Âêà„Å´ Issue ÂÅ¥„ÅÆÂÄ§„Çí„Ç≥„Éî„Éº„Åô„Çã"""
    want = ["Priority", "Target Date", "Sprint"]
    pr_map = extract_field_value_map(pr_item.get("fieldValues", []))
    issue_map = extract_field_value_map(issue_item.get("fieldValues", []))
    for fname in want:
        pr_v = pr_map.get(fname)
        issue_v = issue_map.get(fname)
        if (pr_v is None or pr_v == "") and issue_v:
            fmeta = field_catalog.get(fname)
            if not fmeta:
                continue
            if fmeta["type"] == "SINGLE_SELECT":
                opt_id = fmeta.get("options", {}).get(issue_v)
                if opt_id:
                    update_single_select(pr_item["projectId"], pr_item["id"], fmeta["fieldId"], opt_id)
            elif fmeta["type"] == "DATE":
                update_date(pr_item["projectId"], pr_item["id"], fmeta["fieldId"], issue_v)
            elif fmeta["type"] == "ITERATION":
                it_id = fmeta.get("iterations", {}).get(issue_v)
                if it_id:
                    update_iteration(pr_item["projectId"], pr_item["id"], fmeta["fieldId"], it_id)

def get_assignee_user_ids_for_pr(pr_node_id: str) -> List[str]:
    """PR „ÅÆ„Ç¢„Çµ„Ç§„É≥Ê∏à„Åø„É¶„Éº„Ç∂„Éº ID „ÇíÂèñÂæó„Åô„Çã"""
    query = (
        "query($ID:ID!){ node(id:$ID){ ... on PullRequest { assignees(first:100){ nodes { id } } } } }"
    )
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"ID={pr_node_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("assignees", {})
            .get("nodes", [])
        )
        return [n.get("id") for n in nodes if n.get("id")]
    except Exception as e:
        logger.error(f"PR „Ç¢„Çµ„Ç§„É≥ÂèñÂæó„Å´Â§±Êïó: {e}")
        return []

def get_assignee_user_ids_for_issue(issue_node_id: str) -> List[str]:
    """Issue „ÅÆ„Ç¢„Çµ„Ç§„É≥Ê∏à„Åø„É¶„Éº„Ç∂„Éº ID „ÇíÂèñÂæó„Åô„Çã"""
    query = (
        "query($ID:ID!){ node(id:$ID){ ... on Issue { assignees(first:100){ nodes { id } } } } }"
    )
    try:
        res = run_gh([
            "gh", "api", "graphql",
            "-f", f"query={query}",
            "-f", f"ID={issue_node_id}",
        ])
        nodes = (
            json.loads(res)
            .get("data", {})
            .get("node", {})
            .get("assignees", {})
            .get("nodes", [])
        )
        return [n.get("id") for n in nodes if n.get("id")]
    except Exception as e:
        logger.error(f"Issue „Ç¢„Çµ„Ç§„É≥ÂèñÂæó„Å´Â§±Êïó: {e}")
        return []

def add_assignees_to_assignable(assignable_id: str, user_ids: List[str]) -> None:
    """ÊåáÂÆö„Åó„Åü assignable „Å´„É¶„Éº„Ç∂„Éº„Çí„Ç¢„Çµ„Ç§„É≥„Åô„Çã"""
    mutation = (
        "mutation($A:ID!,$U:[ID!]!){ addAssigneesToAssignable(input:{assignableId:$A,assigneeIds:$U}){clientMutationId} }"
    )
    try:
        run_gh([
            "gh", "api", "graphql",
            "-f", f"query={mutation}",
            "-f", f"A={assignable_id}",
            # assigneeIds „Å´„ÅØ JSON ÈÖçÂàó„Çí„Åù„ÅÆ„Åæ„ÅæÊ∏°„Åô
            "-f", f"U={json.dumps(user_ids)}",
        ])
    except Exception as e:
        logger.error(f"„Ç¢„Çµ„Ç§„É≥ËøΩÂä†„Å´Â§±Êïó: {e}")

def sync_pr_assignees_if_empty_from_issue(pr_node_id: str, issue_node_id: str) -> None:
    """PR „Å´„Ç¢„Çµ„Ç§„É≥„ÅåÁÑ°„ÅÑÂ†¥Âêà Issue „ÅÆ„Ç¢„Çµ„Ç§„É≥„Çí„Ç≥„Éî„Éº„Åô„Çã"""
    pr_assignees = get_assignee_user_ids_for_pr(pr_node_id)
    if pr_assignees:
        return
    issue_assignees = get_assignee_user_ids_for_issue(issue_node_id)
    if issue_assignees:
        add_assignees_to_assignable(pr_node_id, issue_assignees)

def main(output_dir: str, repo: str = "") -> None:
    os.makedirs(output_dir, exist_ok=True)
    # ÂèñÂæóÂØæË±°„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÇíÊ±∫ÂÆö„Åó„ÄÅgh „Ç≥„Éû„É≥„ÉâÁî®„ÅÆÂºïÊï∞„Å®Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç„ÇíÁµÑ„ÅøÁ´ã„Å¶„Çã
    if repo:
        repo_arg = ["--repo", repo]
        file_suffix = repo.replace("/", "_")
    else:
        repo_env = os.environ.get("GITHUB_REPOSITORY", "")
        repo = repo_env
        repo_arg = ["--repo", repo] if repo else []
        file_suffix = repo.replace("/", "_") if repo else "unknown"
    # Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç„Çí <„É™„Éù„Ç∏„Éà„É™Âêç>_PR_status.md ÂΩ¢Âºè„ÅßÁîüÊàê
    output_file = os.path.join(output_dir, f"{file_suffix}_PR_status.md")

    # Áí∞Â¢ÉÂ§âÊï∞ LOGIN_USERS_B64 „Çí„Éá„Ç≥„Éº„Éâ„Åó„Å¶„É¶„Éº„Ç∂„Éº„Å®ÁµÑÁπî„ÅÆÂØæÂøúË°®„Çí‰ΩúÊàê
    login_user_map: Dict[str, str] = {}
    org_order: List[str] = []
    required_reviewers: Set[str] = set()
    encoded = os.environ.get("LOGIN_USERS_B64")
    if encoded:
        try:
            decoded = base64.b64decode(encoded).decode()
            login_users_json = json.loads(decoded)
            logger.debug(
                f"LOGIN_USERS_JSON={json.dumps(login_users_json, ensure_ascii=False)}"
            )  # „Éá„Ç≥„Éº„ÉâÁµêÊûú„ÇíÂá∫Âäõ
            for item in login_users_json.get("loginUsers", []):
                login = item.get("loginUser")
                org = item.get("organization")
                required = item.get("requiredReviewer")
                if login and org:
                    login_user_map[login] = org
                    if org not in org_order:
                        org_order.append(org)
                    if required:
                        required_reviewers.add(login)
        except Exception as e:
            # „Éá„Ç≥„Éº„Éâ„ÇÑ JSON „Éë„Éº„Çπ„Å´Â§±Êïó„Åó„ÅüÂ†¥Âêà„ÅØ„É≠„Ç∞„Å´Ë®òÈå≤„Åó„Å¶Á©∫„ÅÆ„Éû„ÉÉ„Éî„É≥„Ç∞„ÇíÂà©Áî®„Åô„Çã
            logger.error(f"LOGIN_USERS_B64 decode failed: {e}")
    else:
        logger.warning("LOGIN_USERS_B64 is not set")

    # Markdown „ÅÆ„Éò„ÉÉ„ÉÄ„ÇíÂãïÁöÑ„Å´ÁîüÊàê„Åô„Çã
    reviewer_cols = [f"{org} Reviewers" for org in org_order + ["other"]]
    header_cols = [
        "PR",
        "Title",
        "Áä∂ÊÖã",
        *reviewer_cols,
        "Assignees",
        "Status",
        "Priority",
        "Target Date",
        "Sprint",
    ]
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"# Pull Request Status for {repo}\n\n")
        f.write(f"Updated: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\n\n")
        f.write("| " + " | ".join(header_cols) + " |\n")
        f.write("| " + " | ".join(["---"] * len(header_cols)) + " |\n")

    # 1. „Ç™„Éº„Éó„É≥‰∏≠„ÅÆ PR ‰∏ÄË¶ß„ÇíÂèñÂæó
    #    number „ÇÑ title „Å™„Å©„ÅÆÂü∫Êú¨ÊÉÖÂ†±„Çí„Åæ„Å®„ÇÅ„Å¶ JSON ÂΩ¢Âºè„ÅßÂèñÂæó„Åô„Çã
    pr_list_cmd = [
        "gh", "pr", "list", "--state", "open", "--limit", "100",
        "--json", "number,title,author,createdAt,updatedAt,url,isDraft",
    ] + repo_arg
    pr_list_json = run_gh(pr_list_cmd)
    logger.debug(f"PR_LIST={pr_list_json}")
    pr_list = json.loads(pr_list_json)

    for pr in pr_list:
        # 2. PR Ë©≥Á¥∞„ÇíÂèñÂæó
        #    „É¨„Éì„É•„ÉºÂ±•Ê≠¥(reviews)„ÄÅ„É¨„Éì„É•„Éº‰æùÈ†º(reviewRequests)„ÄÅ„Ç¢„Çµ„Ç§„É≥(assignees)„ÇíÂèñÂæó„Åô„Çã
        number = pr["number"]
        title = pr["title"].replace("\n", " ").replace("|", "\\|")
        url = pr["url"]
        is_draft = pr.get("isDraft", False)

        details_cmd = [
            "gh", "pr", "view", str(number), "--json", "reviews,reviewRequests,assignees",
        ] + repo_arg
        details_json = run_gh(details_cmd)
        logger.debug(f"DETAILS for PR {number}={details_json}")
        details = json.loads(details_json)
        reviews = details.get("reviews", [])
        requested = [r["login"] for r in details.get("reviewRequests", [])]
        assignees = [a["login"] for a in details.get("assignees", [])]
        assignees_str = " ".join(assignees) if assignees else "Êú™Ââ≤ÂΩì"

        # „É¨„Éì„É•„ÉØ„Éº„Åî„Å®„ÅÆÊúÄÊñ∞„Çπ„ÉÜ„Éº„Çø„Çπ„Çí‰øùÊåÅ„Åô„ÇãËæûÊõ∏
        reviewer_states = {r: "PENDING" for r in requested}
        # submittedAt „ÅßÊòáÈ†Ü„Å´‰∏¶„ÅπÊõø„Åà„Å¶ÊúÄÊñ∞„É¨„Éì„É•„Éº„ÇíÂèçÊò†„Åô„Çã
        sorted_reviews = sorted(
            reviews, key=lambda x: x.get("submittedAt", "")
        )
        for r in sorted_reviews:
            author = r.get("author")
            if not author:
                continue
            login = author.get("login")
            if not login:
                continue
            # ÁèæÂú®„É¨„Éì„É•„ÉºÂÜç‰æùÈ†º‰∏≠„ÅÆ„É¨„Éì„É•„ÉØ„Éº„ÅØ‰øùÁïôÁä∂ÊÖã„ÅÆ„Åæ„Åæ„Å´„Åô„Çã
            if login in requested:
                continue
            # Âêå‰∏Ä„É¨„Éì„É•„ÉØ„Éº„ÅåË§áÊï∞Âõû„É¨„Éì„É•„Éº„Åó„ÅüÂ†¥Âêà„ÅØÊúÄÂæå„ÅÆÁä∂ÊÖã„ÇíÊé°Áî®„Åô„Çã
            reviewer_states[login] = r.get("state", "")
        # ÁµÑÁπî„Åî„Å®„Å´„É¨„Éì„É•„ÉØ„Éº„ÇíÂàÜÈ°û„ÅóÂêÑÂàó„Å´Ë°®Á§∫„Åô„ÇãÊñáÂ≠óÂàó„ÇíÁîüÊàê„Åô„Çã
        org_groups: Dict[str, List[str]] = {org: [] for org in org_order}
        org_groups["other"] = []
        for reviewer, state in reviewer_states.items():
            org = login_user_map.get(reviewer, "other")
            org_groups.setdefault(org, []).append(
                format_reviewer_status(reviewer, state)
            )

        pr_status = determine_pr_status(reviewer_states, is_draft, required_reviewers)

        # 3. Projects (v2) „ÅÆ„Éï„Ç£„Éº„É´„ÉâÂÄ§„Çí GraphQL „ÅßÂèñÂæó
        #    „Åæ„Åö gh pr view „Åß PR „ÅÆ node ID „ÇíÂèñÂæó„Åô„Çã
        node_cmd = ["gh", "pr", "view", str(number), "--json", "id", "-q", ".id"] + repo_arg
        pr_node_id = run_gh(node_cmd).strip()
        logger.debug(f"PR_NODE_ID for PR {number}={pr_node_id}")

        # „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Ç¢„Ç§„ÉÜ„É†„Å´Á¥ê‰ªò„Åè‰ªªÊÑè„Éï„Ç£„Éº„É´„Éâ„ÇíÂèñÂæó„Åô„Çã„ÇØ„Ç®„É™
        # PullRequest „ÅÆ projectItems „Åã„Çâ fieldValues „ÇíÂàóÊåô„Åó„ÄÅ
        # ÂêÑ„Éï„Ç£„Éº„É´„ÉâÂûã„Åî„Å®„Å´ name/text/date „Å™„Å©„ÅÆÂÄ§„ÇíÂèñ„ÇäÂá∫„Åô
        graphql_query = (
            "query($PR_NODE_ID: ID!) {\n"
            "  node(id: $PR_NODE_ID) {\n"
            "    ... on PullRequest {\n"
            "      projectItems(first: 1) {\n"
            "        nodes {\n"
            "          fieldValues(first: 20) {\n"
            "            nodes {\n"
            "              __typename\n"
            "              ... on ProjectV2ItemFieldSingleSelectValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                name\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldTextValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                text\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldDateValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                date\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldIterationValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                title\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldNumberValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                number\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldMilestoneValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                milestone { title }\n"
            "              }\n"
            "            }\n"
            "          }\n"
            "        }\n"
            "      }\n"
            "    }\n"
            "  }\n"
            "}\n"
        )
        # ‰∏äË®ò„ÇØ„Ç®„É™„Çí gh api graphql „ÅßÂÆüË°å„Åó„Å¶„Éï„Ç£„Éº„É´„ÉâÂÄ§„ÇíÂèñÂæó„Åô„Çã
        try:
            project_json_str = run_gh([
                "gh", "api", "graphql",
                "-f", f"query={graphql_query}", "-f", f"PR_NODE_ID={pr_node_id}",
            ])
            logger.debug(f"PROJECT_JSON for PR {number}={project_json_str}")
            project_json = json.loads(project_json_str)
            field_names = [
                "Status",
                "Priority",
                "Target Date",
                "Sprint",
            ]
            field_values = extract_fields(project_json, field_names)
            status = field_values["Status"]
            priority = field_values["Priority"]
            target_date = field_values["Target Date"]
            sprint = field_values["Sprint"]
        except subprocess.CalledProcessError as e:
            # gh „Ç≥„Éû„É≥„Éâ„ÅåÂ§±Êïó„Åó„ÅüÂ†¥Âêà„ÅØ„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂá∫Âäõ„Åó„ÄÅÂÄ§„Çí "-" „Å®„Åô„Çã
            logger.error(f"PROJECT_JSON fetch failed for PR {number}: {e.stderr}")
            status = priority = target_date = sprint = "-"
        except json.JSONDecodeError as e:
            # JSON „Éë„Éº„Çπ„Å´Â§±Êïó„Åó„ÅüÂ†¥Âêà„ÇÇÂÄ§„Çí "-" „Å®„Åô„Çã
            logger.error(f"PROJECT_JSON parse failed for PR {number}: {e}")
            status = priority = target_date = sprint = "-"

        # Markdown Âá∫ÂäõÁî®„ÅÆË°å„ÇíÁµÑ„ÅøÁ´ã„Å¶„Çã
        row_fields: List[str] = [
            f"#{number}",
            f"[{title}]({url})",
            pr_status,
        ]
        for org in org_order + ["other"]:
            names = org_groups.get(org)
            row_fields.append(" ".join(names) if names else "-")
        row_fields.extend(
            [assignees_str, status, priority, target_date, sprint]
        )
        row = "| " + " | ".join(row_fields) + " |\n"
        with open(output_file, "a", encoding="utf-8") as f:
            f.write(row)

        # PR ÊÉÖÂ†±ÂèéÈõÜÂæå„Å´ Issue „Å®„ÅÆÂêåÊúüÂá¶ÁêÜ„ÇíÂÆüË°å
        try:
            issue_id = get_first_development_issue_id(pr_node_id)
            if issue_id:
                pr_items = get_project_item_map(pr_node_id)
                issue_items = get_project_item_map(issue_id)
                for pid, pr_item in pr_items.items():
                    issue_item = issue_items.get(pid)
                    if not issue_item:
                        continue
                    catalog = get_project_field_catalog(pid)
                    sync_if_empty_same_project(pr_item["item"], issue_item["item"], catalog)
                sync_pr_assignees_if_empty_from_issue(pr_node_id, issue_id)
        except Exception as e:
            logger.error(f"ÂêåÊúüÂá¶ÁêÜ„Å´Â§±Êïó: {e}")

    logger.info(f"PR ÊÉÖÂ†±„Çí {output_file} „Å´Âá∫Âäõ„Åó„Åæ„Åó„Åü")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PR ÊÉÖÂ†±„ÇíÂèéÈõÜ„Åó„Å¶ Markdown „Å´Âá∫Âäõ„Åó„Åæ„Åô")
    parser.add_argument("output_dir", nargs="?", default=".")
    parser.add_argument("--repo", help="ÂØæË±°„Å®„Åô„Çã„É™„Éù„Ç∏„Éà„É™ (owner/name)", default="")
    args = parser.parse_args()
    main(args.output_dir, args.repo)
