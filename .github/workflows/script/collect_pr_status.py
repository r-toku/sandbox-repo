#!/usr/bin/env python3
"""ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ã®ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ã— Markdown ã«æ•´å½¢ã—ã¦å‡ºåŠ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

GitHub CLI (`gh`) ã‚’åˆ©ç”¨ã—ã¦ä»¥ä¸‹ã®æƒ…å ±ã‚’åé›†ã™ã‚‹ã€‚

* ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ PR ã®åŸºæœ¬æƒ…å ±
* ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çŠ¶æ³ã‚„å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼
* Projects (v2) ã«ç´ä»˜ããƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤

`--repo` å¼•æ•°ã§å¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒªã‚’æŒ‡å®šå¯èƒ½ã§ã€ãƒªãƒã‚¸ãƒˆãƒªã”ã¨ã® Markdown ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
åé›†ã—ãŸå†…å®¹ã‚’ Wiki ã«æ²è¼‰ã™ã‚‹ãŸã‚ã® Markdown å½¢å¼ã«ã¾ã¨ã‚ã‚‹ã€‚
"""
import argparse
import datetime
import json
import os
import subprocess
import logging
import base64
from typing import List, Dict, Any

# ç’°å¢ƒå¤‰æ•° LOG_LEVEL ã‚’å‚ç…§ã—ã¦ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š
LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL, logging.INFO),
    format="%(levelname)s: %(message)s",
)
logger = logging.getLogger(__name__)

def determine_pr_status(reviews: List[Dict[str, Any]], is_draft: bool) -> str:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‹ã‚‰ PR ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ–‡å­—åˆ—ã‚’åˆ¤å®šã™ã‚‹

    ãƒ‰ãƒ©ãƒ•ãƒˆã§ã‚ã‚Œã°å¸¸ã«ã€Œãƒ‰ãƒ©ãƒ•ãƒˆã€ã¨ã—ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çŠ¶æ…‹ã«å¿œã˜ã¦
    ã€Œæ‰¿èªæ¸ˆã¿ã€ã€Œä¿®æ­£ä¾é ¼ã€ã€Œãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­ã€ã€Œæœªãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã‚’è¿”ã™ã€‚
    """
    if is_draft:
        return "ãƒ‰ãƒ©ãƒ•ãƒˆ"
    approved = [r for r in reviews if r.get("state") == "APPROVED"]
    changes = [r for r in reviews if r.get("state") == "CHANGES_REQUESTED"]
    if approved:
        return "æ‰¿èªæ¸ˆã¿"
    if changes:
        return "ä¿®æ­£ä¾é ¼"
    if reviews:
        return "ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­"
    return "æœªãƒ¬ãƒ“ãƒ¥ãƒ¼"

def format_reviewer_status(reviewer: str, state: str) -> str:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼çŠ¶æ…‹ã«å¿œã˜ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼åã«çµµæ–‡å­—ã‚’ä»˜åŠ ã™ã‚‹"""
    mapping = {
        "APPROVED": "âœ…",
        "CHANGES_REQUESTED": "âŒ",
        "COMMENTED": "ğŸ’¬",
        "PENDING": "â³",
        "": "â³",
    }
    return f"{reviewer}{mapping.get(state, '')}"

def run_gh(args: List[str]) -> str:
    """gh ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—çµæœã‚’æ–‡å­—åˆ—ã§è¿”ã™

    å¤±æ•—æ™‚ã¯æ¨™æº–å‡ºåŠ›ãƒ»æ¨™æº–ã‚¨ãƒ©ãƒ¼ã®å†…å®¹ã‚’è¡¨ç¤ºã—ã¦ `CalledProcessError` ã‚’é€å‡ºã™ã‚‹ã€‚
    """
    result = subprocess.run(args, capture_output=True, text=True)
    if result.returncode != 0:
        # ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ãŒã‚ã‚Œã°å„ªå…ˆã—ã¦è¡¨ç¤ºã—ã€ãªã‘ã‚Œã°æ¨™æº–å‡ºåŠ›ã‚’è¡¨ç¤ºã™ã‚‹
        err_msg = (result.stderr or result.stdout).strip()
        logger.error(f"gh command failed: {err_msg}")
        raise subprocess.CalledProcessError(
            result.returncode, args, output=result.stdout, stderr=result.stderr
        )
    return result.stdout

def extract_fields(project_json: Dict[str, Any], fields: List[str]) -> Dict[str, str]:
    """Projects ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‹ã‚‰æŒ‡å®šã—ãŸé …ç›®ã ã‘ã‚’æŠœãå‡ºã™

    `fieldValues.nodes` ã«ç¾ã‚Œã‚‹è¤‡æ•°ã®å€¤ã‹ã‚‰ã€å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ã¿ã‚’
    æ¢ç´¢ã—ã¦è¿”å´ã™ã‚‹ã€‚å­˜åœ¨ã—ãªã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ "-" ã§åŸ‹ã‚ã‚‹ã€‚
    """
    result = {f: "-" for f in fields}
    nodes = (
        project_json
        .get("data", {})
        .get("node", {})
        .get("projectItems", {})
        .get("nodes", [])
    )
    for n in nodes:
        fv_nodes = n.get("fieldValues", {}).get("nodes", [])
        for fv in fv_nodes:
            name = fv.get("field", {}).get("name")
            if name not in result:
                continue
            number_value = fv.get("number")
            value = (
                fv.get("text")
                or fv.get("date")
                or fv.get("name")
                or fv.get("title")
                or (str(number_value) if number_value is not None else None)
            )
            if value:
                result[name] = value
            elif isinstance(fv.get("milestone"), dict):
                # ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³å€¤ã¯ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–ã‚Šå‡ºã™
                m_title = fv["milestone"].get("title")
                if m_title:
                    result[name] = m_title
    return result

def main(output_dir: str, repo: str = "") -> None:
    os.makedirs(output_dir, exist_ok=True)
    # å–å¾—å¯¾è±¡ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’æ±ºå®šã—ã€gh ã‚³ãƒãƒ³ãƒ‰ç”¨ã®å¼•æ•°ã¨å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’çµ„ã¿ç«‹ã¦ã‚‹
    if repo:
        repo_arg = ["--repo", repo]
        file_suffix = repo.replace("/", "_")
    else:
        repo_env = os.environ.get("GITHUB_REPOSITORY", "")
        repo = repo_env
        repo_arg = ["--repo", repo] if repo else []
        file_suffix = repo.replace("/", "_") if repo else "unknown"
    output_file = os.path.join(output_dir, f"PR_Status_{file_suffix}.md")

    # ç’°å¢ƒå¤‰æ•° LOGIN_USERS_B64 ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨çµ„ç¹”ã®å¯¾å¿œè¡¨ã‚’ä½œæˆ
    login_user_map: Dict[str, str] = {}
    org_order: List[str] = []
    encoded = os.environ.get("LOGIN_USERS_B64")
    if encoded:
        try:
            decoded = base64.b64decode(encoded).decode()
            login_users_json = json.loads(decoded)
            logger.debug(
                f"LOGIN_USERS_JSON={json.dumps(login_users_json, ensure_ascii=False)}"
            )  # ãƒ‡ã‚³ãƒ¼ãƒ‰çµæœã‚’å‡ºåŠ›
            for item in login_users_json.get("loginUsers", []):
                login = item.get("loginUser")
                org = item.get("organization")
                if login and org:
                    login_user_map[login] = org
                    if org not in org_order:
                        org_order.append(org)
        except Exception as e:
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚„ JSON ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦ç©ºã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’åˆ©ç”¨ã™ã‚‹
            logger.error(f"LOGIN_USERS_B64 decode failed: {e}")
    else:
        logger.warning("LOGIN_USERS_B64 is not set")

    # Markdown ã®ãƒ˜ãƒƒãƒ€ã‚’å‹•çš„ã«ç”Ÿæˆã™ã‚‹
    reviewer_cols = [f"{org} Reviewers" for org in org_order + ["other"]]
    header_cols = [
        "PR",
        "Title",
        "çŠ¶æ…‹",
        *reviewer_cols,
        "Assignees",
        "Status",
        "Priority",
        "Target Date",
        "Sprint",
    ]
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"# Pull Request Status for {repo}\n\n")
        f.write(f"Updated: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\n\n")
        f.write("| " + " | ".join(header_cols) + " |\n")
        f.write("| " + " | ".join(["---"] * len(header_cols)) + " |\n")

    # 1. ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ã® PR ä¸€è¦§ã‚’å–å¾—
    #    number ã‚„ title ãªã©ã®åŸºæœ¬æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ JSON å½¢å¼ã§å–å¾—ã™ã‚‹
    pr_list_cmd = [
        "gh", "pr", "list", "--state", "open", "--limit", "100",
        "--json", "number,title,author,createdAt,updatedAt,url,isDraft",
    ] + repo_arg
    pr_list_json = run_gh(pr_list_cmd)
    logger.debug(f"PR_LIST={pr_list_json}")
    pr_list = json.loads(pr_list_json)

    for pr in pr_list:
        # 2. PR è©³ç´°ã‚’å–å¾—
        #    ãƒ¬ãƒ“ãƒ¥ãƒ¼å±¥æ­´(reviews)ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼(reviewRequests)ã€ã‚¢ã‚µã‚¤ãƒ³(assignees)ã‚’å–å¾—ã™ã‚‹
        number = pr["number"]
        title = pr["title"].replace("\n", " ").replace("|", "\\|")
        url = pr["url"]
        is_draft = pr.get("isDraft", False)

        details_cmd = [
            "gh", "pr", "view", str(number), "--json", "reviews,reviewRequests,assignees",
        ] + repo_arg
        details_json = run_gh(details_cmd)
        logger.debug(f"DETAILS for PR {number}={details_json}")
        details = json.loads(details_json)
        reviews = details.get("reviews", [])
        requested = [r["login"] for r in details.get("reviewRequests", [])]
        assignees = [a["login"] for a in details.get("assignees", [])]
        assignees_str = " ".join(assignees) if assignees else "æœªå‰²å½“"

        # ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã”ã¨ã®æœ€æ–°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¿æŒã™ã‚‹è¾æ›¸
        reviewer_states = {r: "PENDING" for r in requested}
        # submittedAt ã§æ˜‡é †ã«ä¸¦ã¹æ›¿ãˆã¦æœ€æ–°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åæ˜ ã™ã‚‹
        sorted_reviews = sorted(
            reviews, key=lambda x: x.get("submittedAt", "")
        )
        for r in sorted_reviews:
            author = r.get("author")
            if not author:
                continue
            login = author.get("login")
            if not login:
                continue
            # ç¾åœ¨ãƒ¬ãƒ“ãƒ¥ãƒ¼å†ä¾é ¼ä¸­ã®ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã¯ä¿ç•™çŠ¶æ…‹ã®ã¾ã¾ã«ã™ã‚‹
            if login in requested:
                continue
            # åŒä¸€ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ãŒè¤‡æ•°å›ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸå ´åˆã¯æœ€å¾Œã®çŠ¶æ…‹ã‚’æ¡ç”¨ã™ã‚‹
            reviewer_states[login] = r.get("state", "")
        # çµ„ç¹”ã”ã¨ã«ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã‚’åˆ†é¡ã—å„åˆ—ã«è¡¨ç¤ºã™ã‚‹æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹
        org_groups: Dict[str, List[str]] = {org: [] for org in org_order}
        org_groups["other"] = []
        for reviewer, state in reviewer_states.items():
            org = login_user_map.get(reviewer, "other")
            org_groups.setdefault(org, []).append(
                format_reviewer_status(reviewer, state)
            )

        pr_status = determine_pr_status(reviews, is_draft)

        # 3. Projects (v2) ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’ GraphQL ã§å–å¾—
        #    ã¾ãš gh pr view ã§ PR ã® node ID ã‚’å–å¾—ã™ã‚‹
        node_cmd = ["gh", "pr", "view", str(number), "--json", "id", "-q", ".id"] + repo_arg
        pr_node_id = run_gh(node_cmd).strip()
        logger.debug(f"PR_NODE_ID for PR {number}={pr_node_id}")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã«ç´ä»˜ãä»»æ„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å–å¾—ã™ã‚‹ã‚¯ã‚¨ãƒª
        # PullRequest ã® projectItems ã‹ã‚‰ fieldValues ã‚’åˆ—æŒ™ã—ã€
        # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‹ã”ã¨ã« name/text/date ãªã©ã®å€¤ã‚’å–ã‚Šå‡ºã™
        graphql_query = (
            "query($PR_NODE_ID: ID!) {\n"
            "  node(id: $PR_NODE_ID) {\n"
            "    ... on PullRequest {\n"
            "      projectItems(first: 1) {\n"
            "        nodes {\n"
            "          fieldValues(first: 20) {\n"
            "            nodes {\n"
            "              __typename\n"
            "              ... on ProjectV2ItemFieldSingleSelectValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                name\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldTextValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                text\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldDateValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                date\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldIterationValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                title\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldNumberValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                number\n"
            "              }\n"
            "              ... on ProjectV2ItemFieldMilestoneValue {\n"
            "                field { ... on ProjectV2FieldCommon { name } }\n"
            "                milestone { title }\n"
            "              }\n"
            "            }\n"
            "          }\n"
            "        }\n"
            "      }\n"
            "    }\n"
            "  }\n"
            "}\n"
        )
        # ä¸Šè¨˜ã‚¯ã‚¨ãƒªã‚’ gh api graphql ã§å®Ÿè¡Œã—ã¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’å–å¾—ã™ã‚‹
        try:
            project_json_str = run_gh([
                "gh", "api", "graphql",
                "-f", f"query={graphql_query}", "-f", f"PR_NODE_ID={pr_node_id}",
            ])
            logger.debug(f"PROJECT_JSON for PR {number}={project_json_str}")
            project_json = json.loads(project_json_str)
            field_names = [
                "Status",
                "Priority",
                "Target Date",
                "Sprint",
            ]
            field_values = extract_fields(project_json, field_names)
            status = field_values["Status"]
            priority = field_values["Priority"]
            target_date = field_values["Target Date"]
            sprint = field_values["Sprint"]
        except subprocess.CalledProcessError as e:
            # gh ã‚³ãƒãƒ³ãƒ‰ãŒå¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›ã—ã€å€¤ã‚’ "-" ã¨ã™ã‚‹
            logger.error(f"PROJECT_JSON fetch failed for PR {number}: {e.stderr}")
            status = priority = target_date = sprint = "-"
        except json.JSONDecodeError as e:
            # JSON ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã‚‚å€¤ã‚’ "-" ã¨ã™ã‚‹
            logger.error(f"PROJECT_JSON parse failed for PR {number}: {e}")
            status = priority = target_date = sprint = "-"

        # Markdown å‡ºåŠ›ç”¨ã®è¡Œã‚’çµ„ã¿ç«‹ã¦ã‚‹
        row_fields: List[str] = [
            f"#{number}",
            f"[{title}]({url})",
            pr_status,
        ]
        for org in org_order + ["other"]:
            names = org_groups.get(org)
            row_fields.append(" ".join(names) if names else "-")
        row_fields.extend(
            [assignees_str, status, priority, target_date, sprint]
        )
        row = "| " + " | ".join(row_fields) + " |\n"
        with open(output_file, "a", encoding="utf-8") as f:
            f.write(row)

    logger.info(f"PR æƒ…å ±ã‚’ {output_file} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PR æƒ…å ±ã‚’åé›†ã—ã¦ Markdown ã«å‡ºåŠ›ã—ã¾ã™")
    parser.add_argument("output_dir", nargs="?", default=".")
    parser.add_argument("--repo", help="å¯¾è±¡ã¨ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒª (owner/name)", default="")
    args = parser.parse_args()
    main(args.output_dir, args.repo)
